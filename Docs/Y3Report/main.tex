%%%%%%%%%%%%%%%%%% USAGE INSTRUCTIONS %%%%%%%%%%%%%%%%%%
% - Compile using LuaLaTeX and biber, unless there is a particular reason not to. Do not use the older LaTex/PDFLaTeX or BibTeX. (The fonts won't work correctly.)
% - Font and the report 'year' must be specified when all \documentclass or the template won't work correctly. (There's no error checking/default cases!)
% - For best performance save images/graphics as PDF files, not as png/jpg/eps. This makes no difference to how images are inserted using \includegraphics.
% - As many further packages as wanted can be loaded. Below are just an example set. Note that template itself loads a number of packages, including hyperref.
% - References are handed using biblatex.
% - Link to the presentation of theses policy: https://documents.manchester.ac.uk/DocuInfo.aspx?DocID=2863

%%%%%%%%%%%%%%%%%% META DATA SETUP %%%%%%%%%%%%%%%%%%
% This is where the document title and author are set. Other details for the title page are set later
% Note that if/when you edit these you may need to 'Recompile from scratch' to get the changes to display in the PDF. (In Overleaf, select the down arrow to the right of the 'Recompile' button)

    \begin{filecontents*}{\jobname.xmpdata}
        \Language{en-GB}
        \Copyrighted{True}
        % More meta-data fielda can be added here if wanted, see https://ctan.org/pkg/pdfx?lang=en for fields
    \end{filecontents*}

    %%%%%%%%%%%%%%%%%% DOCUMENT SETUP %%%%%%%%%%%%%%%%%%
    \documentclass[12pt]{uom_eee_dissertation_casson} 
    %%%%%%%%%%%%%%%%%% PACKAGES AND COMMANDS %%%%%%%%%%%%%%%%%%
    % Packages
    \usepackage{graphicx,psfrag,color} % for postscript graphics files
        \graphicspath{ {./images/} }   % where to look for images
    \usepackage{amsmath}               % assumes amsmath package installed
        \allowdisplaybreaks[1]         % allow eqnarrays to break across pages
    \usepackage{amssymb}               % assumes amsmath package installed 
    \usepackage{url}                   % format hyperlinks correctly
    \usepackage{rotating}              % allow portrait figures and tables
    \usepackage{multirow}              % allows merging of rows in tables
    \usepackage{lscape}                % allows pages to be typeset in landscape mode
    \usepackage{tabularx}              % allows fixed width tables
    \usepackage{verbatim}              % enhanced version of built-in verbatim environment
    \usepackage{footnote}              % allows more control over footnote environments
    \usepackage{float}                 % allows H option on floats to force here placement
    \usepackage{booktabs}              % improve table line spacing
    \usepackage{lipsum}                % for adding dummy text here
    \usepackage[base]{babel}           % for proper hypthenation in lipsum sections
    \usepackage{subcaption}            % for multiple sub-figures in a single float
    % Add your packages here
    %\usepackage{pdfcomment}            % for alt text for accessibility
    \usepackage{booktabs}              % for better looking tables
    \usepackage[ruled,vlined]{algorithm2e}


    % Then to add images use:
    % \pdftooltip{\includegraphics[width=0.5\textwidth]{image.pdf}}{Alt-text here}
    % This makes the text in the image non-select-able though (assuming it's a vector file)
    
    % Custom commands
    \newcommand{\degree}{\ensuremath{^\circ}}
    \newcommand{\sus}[1]{$^{\mbox{\scriptsize #1}}$} % superscript in text (e.g. 1st)
    \newcommand{\sub}[1]{$_{\mbox{\scriptsize #1}}$} % subscript in text
    \newcommand{\sect}[1]{Section~\ref{#1}}
    \newcommand{\fig}[1]{Fig.~\ref{#1}}
    \newcommand{\tab}[1]{Table~\ref{#1}}
    \newcommand{\equ}[1]{(\ref{#1})}
    \newcommand{\appx}[1]{Appendix~\ref{#1}}
    %%%%%%%%%%%%%%%%%% REFERENCES SETUP %%%%%%%%%%%%%%%%%%
    % Setup your references here. Change the reference style here if wanted
    \usepackage[style=ieee,backend=biber,backref=true,hyperref=auto]{biblatex}
    % Note backref=true adds a page number (and hyperlink) to each reference so you can easily go back from the references to the main document. You may prefer backref=false if you need to stick strictly to a given reference style
    % Fixes which can't be applied in the .cls file
    \DefineBibliographyStrings{english}{backrefpage = {cited on p\adddot},  backrefpages = {cited on pp\adddot}}
    %  \renewcommand*{\bibfont}{\large}
    % Add more .bib files here if wanted
    \addbibresource{references.bib }
    
    %%%%%%%%%%%%%%%%%% START DOCUMENT %%%%%%%%%%%%%%%%%%

    \begin{document}
    \makeatletter
    \title{Development of Two Wheel Self Balancing Line Following Robot} % title of your thesis
    \author{Winston Scott}
    \studentid{107067151}
    \makeatother                                               
    \wordcount{1000}		                    % use \wordcount{} to set the count, \thewordcount to print in the text
    \maketitle

    %%%%%%%%%%%%%%%%%% LISTS OF CONTENT %%%%%%%%%%%%%%%%%%
    \uomtoc
    \begin{uomterms}
        \textbf{TWSB}:Two Wheel Self Balancing \\
        \textbf{DDMR}:Differential Drive Mobile Robot \\
        \textbf{LQR}:Linear Quadratic Regulator \\
        \textbf{MEMS}:Micro-Electro-Mechanical Systems \\
        \textbf{MPC}:Model Predictive Control \\
        \textbf{MCU}:Microcontroler Unit \\
        \textbf{RPC}:Remote Procedure Call \\
        \textbf{IMU}:Inertial Measurement Unit \\
        \textbf{ppr}:Pulses Per Revolution \\
        \textbf{KF}:Kalman Filter \\
    \end{uomterms}

    %%%%%%%%%%%%%%%%%% ABSTRACT %%%%%%%%%%%%%%%%%%
    \begin{abstract} % put abstract here. Limit is 1 page.
        The highly dynamic Two Wheel Self Balancing Robot 
        (TWSB) has a large exploration space for developing high level 
        control strategies. 
        This report presents the design decisions and algorithms developed for
        an autonomous line racing TWSB robot utilizing a monocular vision system with low cost hardware. 
        System identifications techniques are used to explore
        cascaded PID and LQG control strategies.
        A trajectory generation algorithm is proposed based on drivability, confidence 
        and prominence of the detected line from a camera used as an intensity sensor. 
        The performance of the the system is shown to be robust to different race tracks which
        surface texture variation, lighting conditions, high speed straights and tight curves. 
  \end{abstract}%
  \clearpage

  \uomdeclarations

  %%%%%%%%%%%%%%%%%% SECTION 1 %%%%%%%%%%%%%%%%%%
    \section{Introduction}
    The Two Wheel Self Balancing (TWSB) system is a nonlinear, underactuated system that is dynamically stable.
    Compared to the differential drive mobile platform (DDMR), the TWSB requires active control effort
    to maintain its upright posture while in motion and when stationary.
    Substantial research, has been conducted on the similarly unstable 1-DOF inverted pendulum on a cart 
    as a benchmark for control techniques \cite{boubaker2013inverted}. 
    The TWSB robot serves as a cost-effective platform for research and education in complex control 
    strategies less commonly applied to statically stable wheeled robots \cite{educationPlatform}.
    
    Controlling this unstable degree of freedom expands the range of autonomous behaviors that 
    can be explored \cite{RoboLimbo} \cite{jeong2008wheeled} \cite{Browning2004TurningSI}. 
    These behaviors necessitate a hierarchical design in the system's architecture,
    where planning and navigation algorithms though linked, are decoupled by levels of abstraction 
    from the low-level stability control and even lower level motor control. This paper explores 
    the design tradeoffs at each of these levels, and the challenges with developing a robust system 
    capable of autonomous navigation in a variety of indoor environments using a monocular camera.
    
    A notable work on the TWSB system is \cite{grasser2002joe} which designed a TWSB robot capable of disturbance
    rejection and static stability on an inclined plane. This was implemented using an FPGA-based DSP system.
    By decoupling the balancing and steering torques in state space an optimum Linear Quadratic Regulator (LQR), the platform 
    is able to turn about its center effectively.
    An early challenge in the navigation of the TWSB system identified by \cite{SelfContainedMobileTWSB} is the sensor 
    system used for state estimation. The proposed solution uses a gyroscope as a angular rate sensor, which was noted to suffer
    from drift. Accounting for this drift as a linear function over time, the authors were able to stabilize the system and
    teleoperated it over short distances. 

    Advances in the cost-to-performance of embedded systems and micro-electromechanical sensors (MEMS) \cite{MEMS} 
    have allowed \cite{juang2013design} \cite{Velazquez2016VelocityAM} to control the TWSB system 
    using low-powered microcontrolers. 
    Recent research has also applied reinforcement learning to the TWSB system \cite{kober2013reinforcement}.
    Neural networks are proposed as nonlinear function approximations to model the system's response. 
    These methods demonstrate robustness to un-modeled dynamics \cite{guo2021optimal}.

    In mobile robotics, the ability to navigate requires perception. LIDARs are commonly used, as  
    the information they capture naturally lends itself to path-planning algorithms [].
    Another commonly used multimodal sensor is the CMOS camera, which measures light intensity at each pixel. 
    When paired in stereo, it can efficiently infer depth [], providing a suitable alternative to the point 
    clouds generated by LIDAR. Although monocular vision systems are desirable due to their simplicity, 
    the redundancy of stereo vision proves beneficial in safety-critical applications [].
    Both sensors provide rich environmental data that can be leveraged to develop long-term path-planning algorithms.
    
    This paper presents the design of a TWSB robotic platform capable of autonomously navigating an 
    indoor line track. A racing algorithm is proposed,
    based on three key metrics of the line: drivability, confidence, and prominence.
    \cite{visionlinetwsb} utilizes a camera as a matrix of binary intensity sensors and a rule-based 
    algorithm to follow a line while balancing. A similar approach by \cite{ghani2011two} uses infrared sensors. 
    \cite{nntwsbvision} trained an end-to-end neural network to perform the same task. while [] proposes a 
    convolutional neural network-based method that uses RDB-Depth camera data to autonomously 
    navigate with human-centric social behavior. Similarly, [] develops planar-wheeled robot navigation 
    algorithms through lane segmentation using geometric computer vision techniques.
    While considerable success has been achieved by obtaining a linear approximation of the dynamics in a similar fashio to 
    of the classic inverted pendulum, \cite{AdvancedWIP} explores the use of non-linear control strategies, such as backstepping or 
    sliding mode control. An online data-driven model of a mobile system and embeds it 
    in a Model Predictive Controller (MPC). This adaptive control strategy is robust to the un-modeled 
    environment and plant dynamics, allowing for autonomous aggressive maneuvers along a mapped track.
    
    The platform is demonstrated as a cost-effective solution providing foundation for further research in mobile robotics.
    Autonomy is achieved using a stabilizing feedback controller, with cascaded PID and 
    LQR control strategies explored for balancing and stabilizing the robot's position. 
    Once these requirements are met, the robot can be teleoperated intuitively via a 
    smartphone-based web interface. The remainder of this paper focuses on incorporating 
    multimodal sensor data from the camera to develop line-racing algorithms.
    The robot algorithmically infers and follows an unknown line using a monocular camera. 
    A hardware-in-the-loop software architecture is implemented, enabling telemetry data and control 
    commands to be exchanged between the robot and a remote computer. Visualization of this telemetry
    data provides a straightforward means of validating the robot's performance.
    \pagebreak{}

  %%%%%%%%%%%%%%%%%% SECTION 2 %%%%%%%%%%%%%%%%%%
    \section{Mathematical Modeling} % edit section heading as appropriate
    In this report, the TWSB decomposed into 2 commonly studied 2DOF subsystems, described by Fig.\ref{fig:2DOF} and their behavior is analyzed
    separately.
    Effective control and planning algorithms for such platforms require the designer to obtain a mathematical model describing the behavior
    of the robot.  
    \begin{figure}[h]
        \centering
        \begin{subfigure}[b]{0.4\textwidth}
            \includegraphics[width=\textwidth]{Diagrams/DDMR.pdf}
            \caption{Differential Drive Mobile Robot}
            \label{fig:DDMR}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.4\textwidth}
            \includegraphics[width=\textwidth]{Diagrams/WIP.pdf}
            \caption{Wheeled Inverted Pendulum}
            \label{fig:WIP}
        \end{subfigure}        
        \caption{Robot subsystems}
        \label{fig:2DOF}
    \end{figure}


    \subsubsection{Differential Drive Mobile Robot}
    Wheeled mobile robots are typically restricted to navigation in the 2D Cartesian plane. For small robots 
    this configuration, motion models are often simplified by discounting the non linear dynamics of friction and 
    the inertial forces arising from acceleration in the $X'$ direction are negligible \cite{KinematicWheeled}. 

    The DDMR's nonlinear kinematics are obtained from Fig.\ref{fig:DDMR} describe point $G=(x_g,y_g)$ as the position of 
    the robot in the global frame.
    \begin{equation}
        \begin{bmatrix}
            \dot x_g \\
            \dot y_g \\
            \dot \psi
        \end{bmatrix}
        =
        \begin{bmatrix}
            \cos(\psi) & 0 \\
            \sin(\psi) & 0 \\
            0 & 1
        \end{bmatrix}
        \begin{bmatrix}
            v_g \\
            \omega_g
        \end{bmatrix}
        \label{eq:DDMRGlobal}
    \end{equation}

    Where the angular velocity $\omega_g$ and linear velocity $v_g$ are the control 
    inputs to the system. 

    The motion of the DDMR is bounded by its non-holonomic constraints, 
    preventing lateral movement along the $Y'$ axis. 
    Under the pure rolling assumption,the wheels do not slip, the robot's kinematics 
    are governed by the wheel radius $r$ and wheelbase $d$. These parameters define 
    the mapping between the left and right wheel velocities, $\omega_L$ and $\omega_R$, 
    and the global velocities $v_g$ and $\omega_g$, by:
    \begin{equation}
        \begin{bmatrix}
            v_g \\
            \omega_g
        \end{bmatrix}
        =
        \begin{bmatrix}
            \frac{r}{2} & \frac{r}{2} \\
            \frac{r}{d} & -\frac{r}{d}
        \end{bmatrix}
        \begin{bmatrix}
            \omega_L \\
            \omega_R
        \end{bmatrix}
        \label{eq:DDMR}
    \end{equation}

    
    \subsection{DC Motor Model}    
    The robot is driven by two DC motors,through planetary gearboxes, as shown in Fig.~\ref{fig:DCMotor}.
    When a voltage $V_a$ is applied, the DC motor generates a torque, $\tau$, 
    proportional to the armature current, $i_a$.
    According to Lenz's law, the back electromotive force (emf), $e_a(t)$, 
    opposes the applied voltage. These relations are given by:
    \begin{subequations}
        \begin{align}
            \tau &= K_t i_a \\
            e_a &= K_e \dot{\phi}_r
        \end{align}
    \end{subequations}
    where $\dot{\phi}_r$ represents the rotor's angular velocity. The torque 
    and back emf constants are denoted as $K_t$ and $K_e$, respectively.
    \begin{figure}[H]
        \centering
            \includegraphics[width=0.75\textwidth]{Diagrams/DcMotorModel.pdf}
        \caption{Gearbox DC Motor Model Diagram}
        \label{fig:DCMotor}
    \end{figure}
    The ratio between the inductance $L_a$ and armature resistance $R_a$ 
    determines the time constant $\tau_e$ of the motor, that is, the time required 
    for $i_a$ to reach 63.2\% of its final value. In small motors, $\tau_e$ is 
    small, and since $L_a \ll R_a$, the electrical dynamics can be approximated as:
    \begin{equation}
        i_a (t) = \frac{V_a (t) - K_e \dot{\phi}_r (t)}{R_a}
    \end{equation}

    The rotor torque, $\tau_r$, is transmitted through the gearbox, which 
    reduces the angular velocity of the wheel, $\dot{\phi}_w$, by the gear ratio $n = \frac{N_2}{N_1}$. 
    Assuming the gearbox is lossless the wheel torque, $\tau_w$, is given by:
    \begin{equation}
            \tau_w = n\tau_r
    \end{equation}
    where $N_1$ and $N_2$ are the number of teeth on the input and output gears, respectively.
    The rotor's inertia $J_r$ and damping $B_r$ are considered negligible.
    By summing the torques of the rotor and gearbox subsystems, the output torque is given as:
    \begin{equation}
        \tau_w = - J_g \ddot{\phi}_w - \dot{\phi}_w \left( \frac{K_t K_e}{R_a} n^2 + B_g \right) + \frac{n K_t V_a}{R_a}
    \end{equation}
    where $J_g$ represents the gearbox's inertia and $B_g$ its damping coefficient.

    \subsection{Wheeled Inverted Pendulum}
    The wheel inverted pendulum (WIP), is similar to the classic inverted pendulum on a cart. 
    The WIP is composed of 2 rigid bodies, the body and the chassis connected by a revolute joint, 
    at the center of mass of the wheel as shown in Fig.\ref{fig:WIP}. 
    The center of mass of the body, $B=(x_b,z_b)$, 
    is located at a distance $L$ from the wheel's axel, displaced at some pitch angle $\theta$ with 
    the vertical axis $Z$. The body is assumed to be a point mass $M_b$ with a moment of inertia $J_b$ 
    about the axis of rotation. 
    
    The system of equations governing the time evolution of the WIP are 
    commonly found by Lagrangian mechanics \cite{AdvancedWIP}. This is an energy-based approach that
    facilitates describing losses in the system in a general manner through a 
    dissipative term \cite{frankovsky2017modeling} \cite{ModelingWIPLagrange}.
    \begin{equation}
        D = \frac{b_w}{r^2} \dot{x}^2
    \end{equation}
    Following this approach, the system is linearized about the vertical equilibrium position $\theta = 0$,
    yielding the following coupled differential equations of motion:

    \begin{subequations}
        \begin{align}
            \tau_R + \tau_L &= - M_b L \ddot{x}  
            - (M_b L^2 + J_b) \ddot{\theta}  
            + g M_b L \theta, \\
            \frac{\tau_R + \tau_L}{r} &= \left( M_b + 2M_w + 2\frac{J_w}{r^2} \right) \ddot{x}  
            + 2\frac{b_w}{r^2} \dot{x}  
            + M_b L \ddot{\theta}.
        \end{align}
        \label{eq:2DOFWIP}
    \end{subequations}

    Where $\tau_R$ and $\tau_L$ are the torques applied to the right and left wheels. 
    The wheel's inertia is denoted by $J_w$, its damping by $b_w$, and its mass by $M_w$. 

    Incorporating the torque produced by each actuator $\tau_w$, 
    and reiterating the no slip condition $\phi_w = \frac{x}{r}$,
    eq(\ref{eq:2DOFWIP}) can be written in state space form as:

    \begin{equation}
        \begin{bmatrix}
            \ddot{x} \\
            \ddot{\theta}
        \end{bmatrix}
        =
        \begin{bmatrix}
            -\frac{b_w}{r^2} & 0 \\
            \frac{1}{M_b L} & -\frac{M_b L + M_w r^2}{M_b L (M_b L^2 + J_b)}
        \end{bmatrix}
        \begin{bmatrix}
            \dot{x} \\
            \dot{\theta}
        \end{bmatrix}
        +
        \begin{bmatrix}
            \frac{1}{M_b L} \\
            \frac{1}{M_b L (M_b L^2 + J_b)}
        \end{bmatrix}
        \tau_w
        \label{eq:2DOF}
    \end{equation}


   

    
    \pagebreak{}


    \section{System Design}
        The Robot must be designed to approximate the wheel inverted pendulum system, many authors 
        construct demonstrators supporting a mass with a structure of lead screw. This allows for experimentation 
        with the systems center of mass and is simple to construct. A proof of concept system was developed in this manner, 
        however the exposed electronics were susceptible to damage during tuning of the balance and navigation algorithms.

        As such the TWSB body is 3D printed out of PLA plastic in 3 parts for minimal assembly.
        The battery pack is quickly swappable and both it and the electronics sub assembly 
        are soft-mounted in a roll cage like housing for protection against impacts. 
        The wheels are protected by wheel arches which serve to minimize risk of damage to the motor. 
        Wiring harnesses are routed through channels to minimize snagging and disconnection from vibrations.
        
        \begin{figure}[H]
            \includegraphics[width=\textwidth]{DesingImgs/bBot Drawing v3.pdf}
            \caption{CAD Drawing of the TWSB system dimensions in mm}
            \label{fig:CAD}
        \end{figure}

        Two brushed DC motors are powered by an H-Bridge IC, DRV7783. 
        The STM32F411RE Microcontroler Unit (MCU) is used to control the 
        motors and monitor the 6 Axis Inertial Measurement Unit (IMU) over I2C. It communicates with the 
        Raspberry Pi 5 over UART via a custom ASCII protocol discussed in section 2.4. 
        The system is powered by a 12V nominal Li-ion Battery pack. A USB-C CC-CV charger is used for quick 
        and accessible recharging, critical for mobile robotics applications. 
        Battery voltage is monitored by the MCU and the pack is protected by a BMS and a 3A poly-fuse.
        A simple circuit adapted from \cite{chu2008designing} is used to safely load share between the battery pack and the charger.

        \subsection{Software Architecture}
        The modern standard for robotics software is the Robot Operating System 2 (ROS2) \cite{Macenski2022RobotOS}. 
        It is composed of several highly configurable applications that are designed to be manged in a distributed system.
        Distributed systems are beneficial in robotics development as they functionally decouple the software components, 
        enabling robust failure recovery and ease of integrating new features. This is useful for this project as 
        the core control and vision systems are developed in parallel. The controls, logs and error recovery systems mandating 
        high availability compared to user interfaces such as the remote control webapp. 
        Whilst this is a powerful tool, it is deemed too complex to learn for meeting the project deadline.
        Nevertheless some core concepts are used such as sharing state by message passing between components, 
        and dynamic parameter configuration to improve testing and data collection. The ZeroMQ middleware is used for 
        timestamped signal stream communication between the computational nodes. 

        The software, written in C++, is managed by systemd as services. 
        Self-diagnosis routines are used for resource monitoring and auto recovery. 
        Programs operate on runtime parameters through Remote Procedure Call (RPC) 
        interface using a GET-SET pattern. This reduces the 
        compile flash debug iteration time. A GStreamer pipeline sets up a video 
        server accessible over LAN. OpenCV is used for optimized image processing.
      
        The firmware is implemented in C using register definitions from the 
        libopencm3 project \cite{BeginningSTM32} as an exercise in low level programming. 
        No dynamic memory allocation is used.
        The resultant binary is 19KB with 892B of RAM used.
       
        The data-acquisition system obtains a timestamped sample of the 
        telemetry values transmitted by the MCU through a serial link, which 
        RPC interface over uart at 230400 baud, 
        it executes commands and publishes telemetry packets at 100Hz.
        Parsing the UART IO buffer can result in non-uniformly sampled data as it
        is constrained by the OS scheduler, thus an event driven system is used to 
        minimize CPU overhead.
        \pagebreak{}
        \subsubsection{Parameters }
        The system parameters are given in table(1). 
        The mass of the sub-components obtained by weighing,
        and estimates of the 3D printed parts mass are given by the slicer software. 
        The CAD files are used in MATLAB's Multibody Simulink environment, which 
        computes the center of mass and the moments of inertia.
        The Motor parameters and estimated as per [] using the manufacturers dataset[] summarized in table(2).
    
        \begin{table} [H]
            \centering
            \begin{tabular}{|c|c|c|c|}
                \hline
                Parameter & Value & Units & Description \\
                \hline
                $m$ & 1.5 & kg & Mass of the body \\
                $l$ & 0.1 & m & Length of the body \\
                $J_b$ & 0.01 & $kgm^2$ & Moment of inertia of the body \\
                $r$ & 0.03 & m & Radius of the wheel \\
                $d$ & 0.132 & m & Wheel base \\
                $R_a$ & 1.5 & $\Omega$ & Resistance of the motor \\
                $K_t$ & 0.01 & Nm/A & Torque constant of the motor \\
                $K_v$ & 0.01 & V/rad/s & Back EMF constant of the motor \\
                $J_w$ & 0.01 & $kgm^2$ & Moment of inertia of the wheel \\
                \hline
            \end{tabular}
            \caption{System Parameters}
        \end{table}

        \subsection{System Identification}
        A set of experiments are conducted to obtain an estimate transfer function of the motors.
        \begin{table}[H]
            \centering
                \begin{tabular}{|r|c|c|c|c|c|c|}
                    \hline 
                    Gear Ratio & Rated Torque & Rated Speed  & Rated Current & Stall Current & Stall Torque \\
                    \hline
                     1:20  & 0.39 Nm & 600 rpm & 500 mA & 2 A & 0.15 Nm/Kg \\
                    \hline
                \end{tabular}
                \caption{Manufacturer Provided Motor Parameters}
        \end{table}
        A telemetry and analysis software system developed in python. It is used as 
        test bench  setup shown in Fig.\ref{fig:SysIDSetUp}, a series of reference 
        ramp, step, sine and chirp inputs are applied to each motor, 
        the resultant input outputs are shown 
        in Fig.\ref{fig:openloop}.
       
        \begin{figure}[H]
            \centering
            \includegraphics[height=0.\textwidth]{SysIDMotorSetUp.png}
            \caption{System Identification Testbench Setup}
            \label{fig:SysIDSetUp}
        \end{figure}
        The test suit contains a timeseries signal generators, with preview and playback functionality.
        The Systems logs and messages are displayed in a terminal window, and the user is able to fully configure 
        each nodes runtime parameters remotely over a network connection, utilizing the RPC ASCII protocol.
        A line plotter, is configured by JSON to display any number of signals.
        This architecture allows for repeatability in obtaining robot data, something 
        is is a challenge in mobile robotics[]. 
        
        This software system is also utilized for huristic tuning of the control
        and vision systems. The program is able to visualize control signal streams in soft real time, 
        and provides a useful insight into the effects of the control system on the plant.

        \begin{figure}[H]
            \centering
            \begin{subfigure}[b]{0.45\textwidth}
            \includegraphics[width=\textwidth]{Graphs/openstep.pdf}
            \caption{Open Loop Step Response}
            \label{fig:openstep}
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.45\textwidth}
            \includegraphics[width=\textwidth]{Graphs/1HzSine.pdf}
            \caption{Open Loop Sine Response}
            \label{fig:opensine}
            \end{subfigure}
            \caption{Open Loop no Load Speed Voltage Experiments}
            \label{fig:openloop}
        \end{figure}


        From these experiments it is clear that the motor is has significant deadzones, 
        and the input output relationship is non linear at low armature voltages. When the motor is operating at 
        its rated current, seen by the experiments in Fig.\ref{fig:speedvolt}, its its linearity is improved. 
        The maximum no load speed within the manufacturers operating range is found to be 8 rotations per second.
        To increase control authority, the motors are powered by 12V, with the armature voltage is modulated by 
        the duty cycle of the PWM signal. The DRV7783 Integrates current sensing and over current protection,
        used to limit the current to the motors to 1.5A.
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5\textwidth]{Graphs/SpeedVoltageCurve.pdf}
            \caption{Speed Voltage Relationship}
            \label{fig:speedvolt}
        \end{figure}
        For stationary balancing of the TWSB robot
        the actuators are required to be operate mostly in a sinusoidal fashion, 
        similar to Fig.\ref{fig:opensine} in order to regulate the pitch angle of the body.
        Considering this a closed loop controller is developed in section 4.1 to regulate the motors speed,
        and maintain the device is it operating region. 

    \section{State Estimation}
    Information about the TWSB system may be obtained from 2 kinds of sources; 
    mathematical models models as in eq(1) which can describe the time evolution of the chosen system variables, 
    and sensors that convert energy arising from a physical property into information. Both of these sources 
    are approximations of the true state. The process of combining multiple sources of information is termed sensor fusion.
    This section evaluates the available methods employed using \textit{proprioceptive} sensors.
    \subsection{Sensors Overview}
        For the TWSB system in eq(\ref{eq:2DOF}) its state variables $\theta$ and $\dot x_b$ can be measured through the onboard IMU 
        and the wheel encoders respectively. 
            
        The motors incorporate a low-cost 12 pulses per revolution (PPR) incremental encoder on the rotor shaft. 
        Further resolution is easily obtained by using the MCU's quadrature 
        peripheral to increment, or decrement, a counter based on the phase transitions.
        Considering the gearbox ratio $n=20$, an effective resolution of 960 PPR is attained.
        The rotational speed of the wheel is computed by sampling the change in the pulse counts
        over a sample period $\Delta t$. Thus the error in the velocity estimate, 
        is inversely proportional sample period, resulting in large errors at low speeds.
        Yet, it is observed that more significant sources of error arise from the mechanical backlash in the gearbox.
        The sample time is set to 2ms, and a low-pass filter is given by the recursive relation
            \begin{equation}
        y_k = \alpha x_k + (1-\alpha)y_{k-1}
                \label{eq:lpf}
            \end{equation}
        Selecting $\alpha = 0.95$, attenuates exponentially sudden deviations in the velocity estimate.

        Utilizing this velocity in the model of the DDMR in eq(\ref{eq:DDMR}) to obtain the
        position of the robot in the cartesian plane as ($x_g,y_g$)is known as odometry.
        There are various sources of errors in 
        this process, arising from assembly imperfections and conditions in 
        the environment which may break the constraints assumed in the kinematics of the DDMR.
            
        These conditions become significant in the case of the TWSB system as crashes, or bumps, result in large 
        and unbounded error accumulation. In the case of crashes, the robot is subsequently stationary 
        and its state is reset. However, in the case of bumps, where the robot can recover, corrective 
        action is required to mitigate this. Assuming a sufficiently accurate wheel encoder, a simple method is 
        implemented based on \cite{Gyrodometry}, only correcting 
        the odometry when such events are detected.  
        This leads to the decision that other forms of systematic odometry errors have to be 
        either disregarded in the short term or corrected by landmark methods by $exteroceptive$ sensors. 

        The IMU is a 6 axis MEMS sensor[] which measures the local linear acceleration 
        and angular velocity.
        The 3D acceleration $\vec{a}$ is used to obtain an 
        estimate of the pitch angle as    $\hat{\theta} = \mathrm{atan2}\left(-a_x ,a_z \right)$

        The variance of this $\hat{\theta}$ is small when the system is at rest, but grows larger when subject to vibration from the motors
        as shown by the experiment in Fig.\ref{fig:accelNoise} where the TWSB is placed horizontally at rest and motor control commands are issued. 
        \begin{figure}[H]
            \centering
            \begin{subfigure}[b]{0.5\textwidth}

                \includegraphics[width=\textwidth]{Graphs/accelNoiseReadings.pdf}
                \caption{Accelerometer is sensitive to motor vibrations}
                \label{fig:accelRaw}
                
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{Graphs/noisyPitchEst.pdf}
                \caption{Wide Variance on pitch estimate at rest}
                \label{fig:pitchNoise}
            \label{fig:accelNoise}
            \end{subfigure}
            \caption{Accelerometer Noise}   
        \end{figure}

        From \ref{fig:pitchNoise} it can be seen that the IMU is not mounted perfectly orthogonal to the body frame. 
        \begin{table}[H]
            \centering
            \begin{tabular}{c c c} 
                \toprule
                $a_{x_0}$ & $a_{y_0}$ & $a_{z_0}$ \\
                \midrule
                0.036453 & -0.0021066 & 0.133658 \\
                \bottomrule

            \end{tabular}
            \caption{Accelerometer Mounting Offset (m/s$^{2}$)}
            \label{tab:accelOffset}
        \end{table}
        This systematic error is removed by utilizing calibrated values in table obtained as per \ref{tab:accelOffset}.
        
        
        \pagebreak{}
        \subsection{Kalman Filter}
        The Kalman Filter (KF) and its variants  are widely used in robotics to fuse 
        complementary sources of information \cite{Thrun2005ProbabilisticRobotics} \cite{perez2023quadcopter} \cite{Moore2014AGE}.
        The ordinary KF is applicable to linear systems, as a type of Bayesian filter, 
        the discreet representation of the KF represents current belief $bel(x_k)$ around the true state,
        as a Gaussian whose distribution is parameterized by its mean $\mu_k$ and covariance matrix $P_k$.

        A new measurement is observed at each timestamp through the linear function $z_k = C_k x_k + R_k$. 
        The measurement model $C_k$ is used to map the true state into the measurement space.
        Here the process and measurement noise are Gaussian with zero mean and covariance $Q_k$ and $R_k$ respectively. 
        The Kalman Gain computed as \ref{eq:KalmanGain} provides the optimal weighting between t
        he beliefs from the prediction \ref{eq:KalmanPredict} and the measurement update \ref{eq:KalmanUpdate}.
        

        \begin{subequations}
            \begin{equation}
                \bar{bel}(x_k) = \begin{cases}
                        \bar{\mu}_k = F_k \mu_{k-1} + G_k u_k \\
                        \bar{P}_k = F_k P_{k-1} F_k^T + Q_k
                        \end{cases}
                \label{eq:KalmanPredict}
            \end{equation}
            \begin{equation}
                K_k = \bar{P_k} C_k^T \left(C_k \bar{P_k} C_k^T + R_k \right)^{-1}
                \label{eq:KalmanGain}
            \end{equation}
            \begin{equation}
            bel(x_k) = \begin{cases}
                \mu_k = \bar{\mu}_k + K_k \left(z_k - C_k \bar{\mu}_k \right) \\
                P_k = \left(I - K_k C_k \right) \bar{P}_k
            \end{cases}
            \label{eq:KalmanUpdate}
            \end{equation}
            \label{eq:KalmanAlgorithm}
        \end{subequations}
     
        Even though the state transition model of the TWSB robot is non-linear
        \cite{ooi2003balancing} 
        developed self balancing platforms capable of restricting oscillations about the 
        operating point to $±1$ degree. This one order of magnitude than the worst case pitch limit of $±10$ degrees.
        Beyond this, the small angle approximation is no longer valid, and the system is not locally linear. 

        The state transition model used by the KF, can be choses to model the TWSB system \ref{eq:2DOF} as a step towards 
        full state feedback, or solely the dynamics of the IMU.  Both approaches have had success in the literature[][][]. 
        An alternative approach is to use a simplification of the noise modeling used by classical baysian saticitcs and 
        assume that the noise covariance are time invariant, the complementary filter \cite{ComplimentaryKalman} 
        is a popular choice for this due to its low mathematical complexity. 
     
        The MPU6050 6-Axis IMU can estimate the pitch through the gyroscope measurement $\vec\omega_{gyro}$ and the accelerometer measurement $\vec a_{x}$.

        \begin{equation}
            \begin{aligned}
                \begin{bmatrix}
                    \theta_{g{k}} \\
                    \beta_{k} 
                \end{bmatrix}
                &= 
                \begin{bmatrix}
                    1 & -\Delta t \\
                    0 & 1
                \end{bmatrix}
                \begin{bmatrix}
                    \theta_{g{k-1}} \\
                    \beta_{k-1}
                \end{bmatrix}
                +
                \begin{bmatrix}
                    \Delta t \\
                    0
                \end{bmatrix}
                + \begin{bmatrix}
                    -\rho_{k-1}\cdot\Delta t \\
                    \rho_b
                \end{bmatrix}
            \end{aligned}
            \label{eq:gyroBias1}
        \end{equation}
        
        \begin{equation}
            \begin{aligned}
                z_k &= \begin{bmatrix}
                    1 & 0
                \end{bmatrix}
                \begin{bmatrix}
                    \theta_k \\
                    \nu_{g{k}}
                \end{bmatrix}
                + \begin{bmatrix}
                    \rho_{a{k}}
                \end{bmatrix}
            \end{aligned}
            \label{eq:gyroBias2}
        \end{equation}
        

        \begin{figure}[H]
            \centering
            \includegraphics[width=0.8\textwidth]{Graphs/SensorFusion.pdf}
            \caption{Sensor Fusion of accelerometer and gyroscope}
            \label{fig:SensorFusion}
        \end{figure}

        The MPU6050 parameters are obtained from the dataset[] as 
        \begin{table}[H]
            \centering
            \begin{tabular}{|c|c|c|}
                \hline
                Parameter & Value & Units \\
                \hline
                $a_{sensitivity}$ & 16384 & LSB/g \\
                $g_{sensitivity}$ & 131 & LSB/deg/s \\
                \hline
            \end{tabular}
            \caption{MPU6050 Parameters}
        \end{table}
        The kalman gain matrix is obtained operating the motors to simulate typical high frequency conditions 
        and tuning the process and measurement noise matrices.
        \begin{table}[H]
            \centering
            \begin{tabular}{|c|c|c|}
                \hline
                Parameter & Value & Units \\
                \hline
                $Q$ & 0.01 & $rad^2$ \\
                $R$ & 0.01 & $rad^2$ \\
                \hline
            \end{tabular}
            \caption{Kalman Filter Noise Parameters}
        \end{table}

       
        Fig.\ref{fig:SensorFusion} shows that the Kalman Filter's produces a smooth estimate of the pitch angle
        under conditions of the experiment in Fig.\ref{fig:accelNoise}. It is observed that when there is a 
        large change in the motors set-point  the angular momentum built up from the wheels is sufficient to 
        disturb the system from rest seen at $k \approx [170, 380, 580]$.
        \pagebreak{}

    \section{Control System}
        Autonomy in mobile robotics is commonly a hierarchical problem composed of high-level path planning, 
        or task allocation, and low-level control of the actuators.  
        Successful implementations must design solutions to both of these problems in a complementary manner in order 
        to achieve the desired system behavior, of tracking the planned configurations.
            
        For the TWSB robot, behavior can be described by two main goals, static balancing and navigation.
        These two behaviors are inherently coupled due to the system's underactuated design. Hence, the 
        magnitude of the feedback required for sufficiently fast stabilization leads to significant chatter or oscillations 
        in the control signal.

        Gain scheduling is suggested by \cite{refvem2019design}
        as a way to operate the system in these two different modes. A similarly underactuated system is controlled via this 
        method by \cite{wanggain}. Notably, in these cases care must be taken to ensure 
        that discontinuities in the control signal at the point of switching do not cause instability \cite{hespanha2002switching}.
        Determining the switching schedule is a nontrivial problem, often mandating experimental validation-dependent 
        on the systems parameters, \cite{RoboLimbo} utilizes advanced nonlinear strategies to determine these
        boundary conditions.

        The tracking performance of reactive control strategies is bounded by the control effort 
        demanded within the bandwidth of the actuators. Typically in feedback systems, a saturation function 
        is utilized on the reference to enforce safe operation. This discontinuity breaks the linearity of the 
        controller often leading to oscillations, and care must be taken to avoid such limit cycles.
            
        The PID regulator is an attractive choice for many systems, as by nature of negative feedback it does not 
        require an explicit model of the plant to operate. The process variable is typically a direct measurement 
        obtained by a sensor, and the control law $u_k$ is computed reactively to an error signal at each timestamp $k$.
        Oftentimes, intuition about the signal's physical units is sufficient to tune the feedback gains adequately. 
        However, performance validation in the model-free case must be evaluated at runtime, this may prove to be 
        challenging or destructive cases of unstable or safety-critical systems. Huristic methods such as Ziegler-Nichols[]
        formulate approaches to black-box tuning of a plant by observing the system 
        performance under sustained instability and designers experimentally tune such algorithms.
    
        For example, the input-output data of the selected actuators obtained in Fig.\ref{fig:openloop}, 
        it can be seen that a large integral action is needed to overcome the steady-state error.
        This is a common issue in low-cost DC motors, where the static friction of the gearbox presents 
        a nonlinearity which is most notable at low voltages. 
    
        Model-based control allows the designer to validate the performance of the system in simulation. 
        Often frequency domain tools are used to analyze the plan in an open loop. From this, a control law is designed around 
        the controllable state variables with physical information on the behavior of the system.
        Given a model of the system, designers also can formulate constraints, 
        and obtain an optimal control signal which meets these. For example, by minimizing the control effort in a cost function
        the challenges associated with choosing a saturation safety function can be mitigated.
    
        Parameter uncertainty a common issues in controlling mobile robotics, and approximations of these often lead to 
        discrepancies between the mathematical optimal solutions found in simulation \cite{eide2011lqg} 
        and in real world performance \cite{tran2023fuzzy}. The difficulty with purely model-based approaches 
        the need for a high fidelity model, and access to low uncertainty measurements of the state variables.
    
        A model of the TWSB robot, incorporating the non-idealities of low-cost DC motors is proposed by \cite{yamamoto2008nxtway}.
        It is used together with a simulation study of a WIP platform as a reference solution for the TWSB problem.
    
        Another approach is to use actuators with more favorable characteristics for the task at hand, such as stepper motors []. 
        The static balancing problem aims to control $\theta$ and regulate the linear displacement $\dot x_b=v_b$. The coupling of the 
        pitch angle to the rate of change in linear position requires active control, resulting in oscillations in both these state variables. 
        Stepper motors draw a nominal current, thus maintaining high torque at low speeds, eliminating the need for gearboxes and the 
        backlash associated with them. With suitable micro-stepping, shaft position control 
        leads to a smoother reaction to control signals and the TWSB balances about a point without the need to incorporate the  
        TWSB model in the feedback controller design. 
            
        The field of adaptive control proposes dealing with system uncertainties by designing controllers that may 
        learn over time. Online trial-and-error data and statistical techniques like regression-based transfer
        function estimation from input-output data are used to develop physics-informed models taken under statistical 
        distributions of belief \cite{benosman2018model}.         
                
        In a similar vein, \cite{williams2016aggressive} embeds a neural network as an online function approximator to learn 
        predictions of the dynamics of the system. This prediction is then used as part of a trajectory planner in race-line optimization. 
    
        Some modern microcontrolers have sufficient computational power requirements needed for Model Predictive Control (MPC) and 
        effective implementations of convex optimizers \cite{nguyen2024tinympc} have been used in small mobile robots \cite{giernacki2017crazyflie}.
            
        An attractive aspect of predictive approaches to control is that they lend themselves naturally to 
        planning long horizons. These methods utilize numerical simulation techniques to evolve the system over time 
        and estimate the distribution of state probabilities through Monte Carlo sampling of control actions. 
        The optimal control sequence is then chosen from these samples using a cost function.
                
        The autonomous behavior of the TWSB robot explored in this paper is that of path 
        following in an unknown environment, where no prior map is available. As such the 
        control system has three goals, namely disturbance rejection of the pitch angle; 
        this is required such that the system is robust to the environment, minimizing 
        the linear displacement when stationary and tracking a trajectory obtained by a 
        high level planner discussed in section 6. 

        A simple PID controller operating on the pitch error is tested in simscape multibody; 
        a physics based simulation where the control law is an applided force to a prismatic joint. 
        This force is coupled through the revolute joint to the pitch angle as descried by \ref{eq:2DOF}.
        This manages to stabilize the pitch angle yet as shown by fig, $x_b$ position drifts over time.
        More complex control laws are discussed in the following sections.

        \subsubsection{Controler requirements}

        The TWSB achieves balance by controlling the oscillations of the pitch angle about the 
        vertical axis. The linear system of equations in eq. \ref{eq:2DOF} is applicable 
        only when the pitch angle is small, this is taken to be $\theta < ±10$ degrees. 

        The advanced non-linear control methods discussed above are beyond the scope of this project. 
        Whilst their performance guarantees under real-world conditions are attractive, it is often simpler 
        to implement complex behaviors in the high-level planner.

        In the sequence the low level controls are developed to meet these requirements:
        \begin{enumerate}
            \item The pitch angle must be regulated to $±1$ degree.
            \item The global $x$ position should be controlled by a linear velocity reference.
        \end{enumerate}

        \subsection{Cascade PID}
        
        In the planer case shwon in fig Fig.\ref{fig:WIP} the trajectory of the center of mass is parametrized by 
        the pitch angle $\theta$ and the linear velocity $v_b$. 
    

        A cascaded pid controller is used to control the pitch angle and the linear velocity. 
        Control of the position $(x_g,y_g)$ is left to a higher level planner.  
        If the inner loop dynamics are much faster than the outer loop, 
        then the inner loop can be approximated as a disturbance[].

        In order to determine the maximum operating frequency of the outer loop, 
        the inner motor speed loop is closed at 200Hz and the system is observed.
        
        Through the Ziegler-Nichols method[], the PID gains for each DC Motors speed control loop 
        are obtained as shown in table(2). This process however may cause damage to the motors 
        during the sustained oscillations at the critical gain. 
       
        The frequency response of the transfer function is shown in fig(4) 
        and its closed loop bandwidth is determined to be ... rads

        This is then used to obtain the PID gains in table(4) in MATLAB using pole-placement techniques
        \begin{table}[H]
            \centering
            \begin{tabular}{|c|c|c|}
                \hline
                Parameter & Zeigler-Nichols & SysId \\
                \hline 
                $K_p$ & 0.1 & 0.1 \\
                $K_i$ & 0.01 & 0.01 \\
                $K_d$ & 0.01 & 0.01 \\
                \hline
            \end{tabular}
            \caption{PID Gains}
        \end{table}

        A P controller is used to regulate the steering control signal, which modeled
        as a disturbance from the 2D dynamics model.

        The error of the pitch angle is regulated by a PID controller operating at 100Hz. 
        
        This results in a stable system in 1DOF space, controlling the body velocity requires the outermost loop to be closed at 20Hz.
        The final cascaded closed loop pid controller is shown in fig(5) with the gains in table(5)

        \begin{figure}[H]
            \includegraphics[width=\textwidth]{Diagrams/cascade.pdf}
            \caption{Cascaded PID Controller}
        \end{figure}

        \begin{table}[H]
            \centering
            \begin{tabular}{|r|r|r|r|c|c|c|c}
                \hline
                & \multicolumn{5}{c|}{Process Variable}  \\
                \hline
                Parameter & $v_b$ & $\theta$  & $\omega_L$ & $\omega_R$ & $\dot{\psi_b}$ \\
                \hline      
                $K_p$ & 2.2 & 0.19 & 2.4 & 2.9 & 0.8 \\
                $K_i$ & 0.8 & 5.6 & 24.8 & 24.8 & 2\\
                $K_d$ & 0 & 0.003 & 0 & 0  &  0\\
                \hline
            \end{tabular}
            \caption{PID Gains}
        \end{table}
        \pagebreak{}
        \subsection{LQR}
        A Linear Quadratic Regulator (LQR) is used to control the system in 2DOF space.
        This minimizes 
        
       
        Selecting the Q and R matrixes as eq(7) and eq(8) respectively, 
        the K feedback matrix in eq(9) is obtained by solving the Algebraic Riccati
        equation of the discretized system eq(10) in MATLAB.
        sample frequency determine based on rise time of simulated closed loop model. 
        by Nyquist the system must then be sampled at least 200Hz. 

        \pagebreak{}
        \section{Navigation System}
        The TWSB robot is tasked with navigating around a track, marked by a line assumed to be of significant contrast to to its 
        surrounding environment. The performance of the navigation system can be characterized by the cross track error and the lap time, 
        with the former being a critical failure mode, where position diverges significant from the track in a non-recoverable manner.
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.6\textwidth]{TestTrack.pdf}
            \caption{Test Track, (1) Chicane, (2) Hairpin, (3) Wall Proximity, (4) Straight, (5) Shallow Curvature, (6) Apex}
            \label{fig:TestTrack}
        \end{figure}
        The reference track tests common navigation tasks and challenges highlighted in Fig.(\ref{fig:TestTrack}). 
        Here the environment is nonideal as the floor has various textures, marks, and colors.
        Lighting conditions are also nonuniform and the track is physically bounded by walls on all sides, enforcing hard accuracy constraints. 
        When teleoperated using the camera feed, it is challenging to avoid crashes. A human operator with 
        full view of the environment can navigate the robot around the track, at moderate speeds the line is often lost 
        from the camera view. This mandates a corrective action using information about the robot's global pose, 
        which is not available to the TWSB. This track is therefore a suitability challenging test for autonomous mobile navigation.
            
        Map building is a popular approach for mobile navigation in a closed loop as it allows for a large 
        context of the environment to be considered. Closed maps can be built iteratively, by exploration 
        and subsequent loop closure. In this case, guarantees can also be made, 
        such as static obstacle avoidance and path selection by optimization functions \cite{Macenski_2020}. 
        This is referred to as global navigation and often requires advanced localization sensors 
        and algorithms to triangulate the robot's pose within the global environment.
        
        In this report, however, no global map data is available and the robot must navigate 
        the track using only the information obtained from the camera sensor. This is commonly known as local navigation
        and is fundamental to autonomous behavior where it is often impractical to obtain and maintain such a map. Without a map, 
        however, the robot must infer its pose relative to the track, and in cases where the track is not visible, the robot is lost. 
        Robust autonomy must be able to handle cases where the robot is lost, and safely search for the track or remain stationary. 

        Path following is commonly implemented with a lateral and a longitudinal controller. This follows from the 
        inputs and non holonomic constraints of the DDMR system in eq(\ref{eq:DDMRGlobal}).
        The longitudinal controller regulates the linear velocity of the robot where, in the simplest form, the reference speed 
        is set to a constant value, and the lateral controller keeps the robot heading aligned with the track. 
        This method is suitable for simple tracks and low speeds.
        
        In contrast, trajectory tracking is a method that generates some optimum path from the sensed environment and subsequently follows this path.
        This 2 stage process is falls under planning and is useful in cases where the lap time is more important than the cross-track error.
        In racing, the robot has to to perform at the limits of its handling capabilities \cite{wischnewski2022indy}. Hence a method 
        for automatic safety is required, a common method extends planning by predicting the robot's position over some horizon,
        a velocity profile can be then obtained whilst maintaining the robot within certain bounds, often the profile is 
        designed in such a manner to stop the robot at the end of its horizon \cite{williams2016aggressive}. These kinds of model predictive controllers 
        have been demonstrated to have impressive performance but are complex methods that require a high fidelity model of the robot within its environment. 
        The time constraints of this project preclude the exploration of data driven 
        or learning methods employed to build such a model of the TWSB robot. As such a series of reactive controllers are used within different 
        racing-line algorithms based on curvature of the track ahead as baseline methods.
            
        Many local navigation methods rely on obtaining a geometric representation of the track ahead, effectively building a local map.
        Commonly a path can be represented as a piece-wise arc or a form of cubic spline, from which parameters such as curvature, $\kappa$, 
        can be obtained. Simpler methods of path following by monocular camera have been applied to the TWSB robot, these do not measure the 
        geometry of the track, but rather use the image data to classify a set of features and use these in a rule-based algorithm to follow the 
        track, \cite{visionlinetwsb} \cite{ismail2009vision} \cite{nntwsbvision}.
        These methods are found to limit the track to shallow curvature or low speeds as they only utilize a small 
        a subset of the information available from the camera sensor. 

        In this paper a method is developed that obtains a set of track waypoints from a grayscale monocular camera. 
        Whilst these do not predict the future poses of the robot, the nature of the 
        monocular camera sensor's information allows for a dynamic velocity component to be added to path following.

        \subsection{Camera Sensor}
        Geometric information about the track can be observed from a camera sensor mounted on the TWSB robot.
        This obtains a discreet 2D projection of the environment in the form of a matrix of pixels, each of which encodes 
        its value as an 8 bit unsigned integer. Considering such an image, it is non trivial to
        obtain a map of the track with reference to the robot, as the data is highly encoded in a large measurement space. 
        Perceptual sensors of this form differ from the physical sensors found elsewhere on the TWSB robot as the quantity measured; 
        light intensity, is not directly usable as a state variable, except in simple autonomous behavior like photo-taxis \cite{hasslacher1995living}. 

        The question of what quantifies useful information in an image is a long standing problem,  \cite{siegwart2011introduction} classifies 
        perception as the process of condensing the detailed information contained within each image, or sequence of images, 
        into features that are useful to track for the task at hand.
        In the case of monocular mobile navigation, the notion of feature models is a key concept in active perception \cite{Activeperception}.
        These models are used to infer $\textit{percepts}$, which are then used to make decisions in controlling the robots pose within its environment 
        \cite{hutchinson1996tutorial}. 

        The field of computer vision is concerned with the extraction of these percepts from the image data. 
        Classical computer vision algorithms are used to extract spacial information about the sensed environment over the visible 
        horizon. Common features are reasoned by geometry, \cite{lee2009geometric} such as edges, corners, lines and blobs of texture. 
        These are typically processed using a series of 2D convolutional filters, or kernels, which for large images is
        computationally expensive and often requires the use of a GPU to parallelize the operations. In these cases the
        advances in parallel computing have proliferated the use of neural networks in computer vision, which apply a 
        series of latent filters to the image data. These are trained on large datasets of images 
        or online \cite{tai2017virtual} \cite{lee2013line} \cite{kober2013reinforcement}, and aim to simply the process of feature extraction. 
        
        The TWSB is equipped with a Raspberry Pi Camera Module V3, which is a rolling shutter camera. Images are obtained 
        in grayscale directly from the Y plane of the camera driver at 640x480 resolution to improve encoding speed and 
        minimize wireless transmission bandwidth.

        \subsubsection{Calibration}
        Cameras are optical devices and are subject to lens and pixel distortion. Modern cameras are assumed to have square pixels, 
        but still require some calibration to undistort the barrel effect of the lens. 
        The camera is mounted on the TWSB robot at a height of 18cm with an angle of 15 degrees to the floor plane.
        This perspective results in rectangles in the environment being projected into trapezoids.  This makes it difficult to 
        obtain distances between different features identified in the image \cite{tuohy2010distance}
        A top down, orthographic view of the floor plane is is desired, where there is a linear function mapping pixels sizes 
        to real world distances. A chessboard pattern of known dimensions is placed on the floor plane in front of the camera, 
        this encompasses the entire field of view. From the position of the chessboard corners in the image, 
        a homography matrix is obtained which maps the image coordinates to the real world coordinates, 
        resulting in the corrected perspective transform shown in Fig.(\ref{fig:perspective}). 
        This method assumes the pitch angle, and thus its field of view of the camera to be constant, it it diverges too much the 
        mapping needs to be re-calibrated. 
        \begin{figure}[H]
            \centering
            \includegraphics[width=0.6\textwidth]{visionpipeline/WallCuveLeft.png}
            \caption{Perspective Correction}
            \label{fig:perspective}
        \end{figure}

        \pagebreak{}
        \subsection{Track Detection}
        The robot must be able to obtain an estimate of where the track line is, relative to its forward direction.
        In non ideal environments, significant noise is present in the image data, 
        and simple edge thresholding methods[] are not sufficient. This noise can lead large errors
        in the estimated position of the track. The information in the image needs to be condensed into a set of features
        which describe the track. Summing the pixels values in each column, a distribution of the edges 
        across the image is found. The ideal straight line can be thought of as a single peak in the center of the frame.  
        It can be seen in Fig.\ref{fig:Line Detection and Segmentation} that this method results in peaks of different 
        shapes depending on the curvature of the track, however the track position in the image plane is readily 
        segmented by the peaks topological prominence, that is the difference between 
        a peak and the local minima around it. 
        \begin{figure}[H]
            \centering
            \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{visionpipeline/vizSmallCurve.png}
                \caption{Low Curvature}
                \label{fig:LineDetection}
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{visionpipeline/vizBigCurve.png}
                \caption{Sharp Curvature}
                \label{fig:Sharp Curvature}
            \end{subfigure}
            \caption{Line Detection and Segmentation}   
        \end{figure}

        Some challenging cases, where simpler methods may fail, are shown in 
        Fig.\ref{fig:ChallengingEnvironments}. Here it can be seen that these cases have a higher noise floor, 
        that is the the peak is not as prominent. This prominence can be used as as an indicator of the confidence that 
        the peak is the true position of the track. 

        \begin{figure}[H]
            \centering
            \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{visionpipeline/vizFalsePos.png}
                \caption{False Positives}
                \label{fig:FalsePositives}
            \end{subfigure}
            \hfill
            \begin{subfigure}[b]{0.45\textwidth}
                \includegraphics[width=\textwidth]{visionpipeline/vizLightOclusion.png}
                \caption{Reflective Occlusion}
                \label{fig:ReflectOcclusion}
            \end{subfigure}
            \caption{Challenging Environments}
            \label{fig:ChallengingEnvironments}
        \end{figure}

        False positive as shown in Fig.(\ref{fig:FalsePositives}) are a serious issue with line detection algorithms as 
        they often cause the robot to loose track of the original path in a non recoverable manner.
        These are difficult to remove once present in the 1D histogram of the edges, as they form peaks of similar shapes to desired features. 
        This non unique mapping of data to a set of features is a common issue in robotic perception, as such the control and perception methods 
        must be co designed to reject these robustly.
        
        From these images 3 sources of noise features are identified: salt and pepper noise, arising mainly through impulses in texture 
        variation of the floor, objects boundaries resulting in an edge of similar shape to the track, and occlusions from reflections 
        or movement blur stemming from the rolling shutter of the camera.

        Pre-filters like the median filter can be used to remove salt and pepper noise, however this is computationally expensive, taking on average 10ms
        to process a single frame on the selected hardware resulting an the enter pipelining not running in realtime. 
        The proposed vision pipeline uses morphological operators to modify the shape of the features in the image.
        By eroding and dilating these features, the impulse noise is removed, this lowers the median noise floor, increasing the prominence of the peaks. 
        Assuming that the robot is initially on the track, then the search space for the peak representing the track can be expanded around the last
        known position of the track. Subsequently, the track peak is searched for staring at the bottom of the image, and sliding a window upwards, 
        until a large discontinuity is found. This is done by searching for the largest peak in the histogram, warm starting each sections search from the position 
        of the peak found in the section bellow it, and then checking if the next peak is within a certain distance. In this manner
        a series of waypoints on the track is obtained, which as shown in Fig.\ref{fig:LineDetection} are robust to the sources of noise discussed. 
        The algorithm processes each frame and obtains a continuous set of waypoints describing the track on average in 0.15ms when running on the Raspberry Pi 5.
        \begin{figure}[H]
              \centering
              \begin{subfigure}[b]{0.32\textwidth}
                 \includegraphics[width=\textwidth,height=0.2\textheight]{visionpipeline/curverightapprach.png}
                 \caption{Right Curve Approach}
                 \label{fig:appoachRight}
              \end{subfigure}
              \hfill 
              \begin{subfigure}[b]{0.32\textwidth}
                 \includegraphics[width=\textwidth,height=0.2\textheight]{visionpipeline/straightoffsetleft.png}
                 \caption{Off Straight}
                 \label{fig:straight} 
              \end{subfigure}
              \hfill
              \begin{subfigure}[b]{0.32\textwidth}
                 \includegraphics[width=\textwidth,height=0.2\textheight]{visionpipeline/apprachLeft.png}
                 \caption{Exit Chicane}
                 \label{fig:exitChicane}
              \end{subfigure}
              \caption{Path Waypoints}
              \label{fig:PathWayPoints}
           \end{figure}

        \subsection{Racing Algorithms}
            \subsubsection{Lateral Control}
            A bang bang type steering controller is used obtain a baseline track performance. 
            This is a reactive controller which uses the cross track error, obtained via a topological peak tracker as described in section 6.2.
            In this case the velocity target of the robot is set to some constant value. 
            The virtual sensor is applied to a small section of the bottom of the image frame, representing points on the track which are closest to the robot. 
            This manages to navigate the track without loosing it on straights and gentle curves, however it is suffers on
            sharp sequences of curves, chicanes, where the track in the observed section is lost. In this case, by rolling off the last known position 
            of the track towards the center of the image, and setting the velocity target to zero, the robot is able to navigate the track past the chicane.
            
            The robots telemetry odometry is used to build estimate of the path taken by the robot across a series of experiments, Fig.\ref{fig:TrajTrack} shows 
            that performance suffers from oscillations along the straights and overshoots on the curves, here the bold lines represent the estimated robot position,
            $(x_g, y_g)$, and the translucent fill represents the vector of the robot's heading each sample instant $\psi_g$. 
            \begin{figure}[H]
                \centering
                \includegraphics[width=0.7\textwidth]{Graphs/Path Following.pdf}
                \caption{Map built offline using dead reckoning}
                \caption{Lateral Control}
                \label{fig:TrajTrack}
            \end{figure}

            From these laps, described in table \ref{tab:lap_stats} variance of the change in steering control vector between samples is small 
            but increases with speed, together with the large overshoots in heading vector from Fig.\ref{fig:TrajTrack} this indicates 
            that the robots tracking performance is degraded by non smooth control signals so the robot is unable to catch up to the curvature of the track.
            The bang bang nature of this controller can also be seen on the straights, where the control angle oscillates about the centerline.             
            For each target speed 10 laps of the track are performed, at higher speeds the robot is unable to repeatability navigate the track using this method. 
  
            Yet, neglecting errors in path following accuracy, this method is still able to perform laps of the track 
            without loosing the line or crashing into the wall boundary. This can be attributed to 
            the implicit look ahead in the vision system, shown in Fig.\ref{fig:PurePersuit}, where the the bottom of the image frame 
            captures the track some distance ahead of the robot. 
            
            \subsubsection{Adaptive Lookahead and Longitunal control}
            Towards better racing performance, the faliuers cases of understeering on curves and oversteerign on straights 
            are improved in 2 manners. The linear velocity 
            of the robot is inversly proportional to the numer of waypoints found vision system, as this represents much track there is 
            ahead of the robot.  This slows the robot down as it approaches a curve and allows it to accelerate on straights. 
            By entring the cuvers at a lower speed, the robot no longer looses the track from its frame. The chicane poses a challenge as 
            the robot must enter it sloly but it is desirebel to accleerate out of it. Considering that upon enterign the chicane, 
            the logitunal controler slows the robot down, so more of the track is visible, hence in order ot accelrare out of the track 
            the lookahead distance is increased inversly proportional to the number of waypoints. 
            This approach is counter intutive as commonly, on straights the lookead distance is increased 
            and decreased on curves, however in the case of the TWSB robot, when the lookahead distance is too small the dead zone
            in the vision system causes track to leave the image frame on sharp curves such at the apex of
            the chicane shown in Fig.\ref{fig:Chicane}.

                    
            In order to suitably race the TWSB it must be able to quickly and stably decelerate to a stop. Moreover, at sharp corners, the linear velocity must be 
            reduced, as otherwise cornering forces become significant and the TWSB may lose wheel traction, 
            losing balancing control authority and crashing. 
            By increasing the lookahead distance in such a manner  the robot obtains a waypoint which is past the apex of the chicane allowing it to accelerate out 
            of the curve. This late apex racing strategy  is commonly use by human divers, \cite{kegelman2017insights}. 


            \begin{figure}[h]
                \centering
                \includegraphics[width=0.6\textwidth]{Diagrams/PurePersuit.pdf}
                \caption{Local Path Following}
                \label{fig:PurePersuit}
            \end{figure}
    \pagebreak{}


  %%%%%%%%%%%%%%%%%% SECTION 4 %%%%%%%%%%%%%%%%%%
  \section{Results and discussion} % edit section heading as appropriate
    \subsection{Balance Performance}
    \subsection{Race Performance}
            
    \begin{figure} [H]
        \centering
        \begin{subfigure}[b]{0.48\textwidth}
            \includegraphics[width=\textwidth]{Graphs/Trial1.pdf}
            \caption{Trial 1}
            \label{fig:Trial1}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.48\textwidth}
            \includegraphics[width=\textwidth]{Graphs/Trial4.pdf}
            \caption{Trial 2}
            \label{fig:Trial2}
        \end{subfigure}
    \end{figure}

    \subsection{More detail}
    \subsection{Summary}
  %%%%%%%%%%%%%%%%%% SECTION 5 %%%%%%%%%%%%%%%%%%
  \section{Conclusions and future work} % edit section heading as appropriate
    \subsection{Conclusions}
      \subsection{Future work}
  %%%%%%%%%%%%%%%%%% REFERENCES %%%%%%%%%%%%%%%%%%
    \printbibliography
  %%%%%%%%%%%%%%%%%% APPENDICES %%%%%%%%%%%%%%%%%%
  \begin{uomappendix} 
      \section{Code}
      \section{Risk assessment}
      Risk assessment is a required appendix. Put here.
      %\section{Other appendices as necessary}
  \end{uomappendix}
  
  %%%%%%%%%%%%%%%%%% END MATTER %%%%%%%%%%%%%%%%%%
  \end{document}